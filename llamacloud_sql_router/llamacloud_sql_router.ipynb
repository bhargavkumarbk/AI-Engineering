{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining RAG and Text-to-SQL in a Single Query Interface\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llamacloud-demo/blob/main/examples/advanced_rag/llamacloud_sql_router.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This notebook shows you how to create a custom agent that can query either your LlamaCloud index for RAG-based retrieval or a separate SQL query engine as a tool. In this example, we'll use PDFs of Wikipedia pages of US cities and a SQL database of their populations and states as documents.\n",
    "\n",
    "![](llamacloud_sql_router_img.png)\n",
    "\n",
    "**NOTE**: Any Text-to-SQL application should be aware that executing arbitrary SQL queries can be a security risk. It is recommended to take precautions as needed, such as using restricted roles, read-only databases, sandboxing, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Set up your OpenAI API key and `nest_asyncio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Setup Observability\n",
    "\n",
    "We setup an integration with LlamaTrace (integration with Arize).\n",
    "\n",
    "If you haven't already done so, make sure to create an account here: https://llamatrace.com/login. Then create an API key and put it in the `PHOENIX_API_KEY` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-index-callbacks-arize-phoenix\n",
      "  Downloading llama_index_callbacks_arize_phoenix-0.4.0-py3-none-any.whl.metadata (744 bytes)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-callbacks-arize-phoenix)\n",
      "  Downloading llama_index_core-0.12.22-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting openinference-instrumentation-llama-index>=3.0.0 (from llama-index-callbacks-arize-phoenix)\n",
      "  Downloading openinference_instrumentation_llama_index-3.3.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.21.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/lib/python3/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (9.0.1)\n",
      "Collecting pydantic>=2.8.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting openinference-instrumentation>=0.1.17 (from openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading openinference_instrumentation-0.1.23-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting openinference-semantic-conventions>=0.1.9 (from openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading openinference_semantic_conventions-0.1.14-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opentelemetry-api (from openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-instrumentation (from openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions (from openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading aiohappyeyeballs-2.4.8-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (8.0.3)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting opentelemetry-sdk (from openinference-instrumentation>=0.1.17->openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mahesh/.local/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2020.6.20)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: anyio in /home/mahesh/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mahesh/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mahesh/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.14.0)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api->openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/mahesh/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation->openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix) (24.2)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api->openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/mahesh/.local/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/mahesh/.local/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.3.1)\n",
      "Downloading llama_index_callbacks_arize_phoenix-0.4.0-py3-none-any.whl (3.1 kB)\n",
      "Downloading llama_index_core-0.12.22-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openinference_instrumentation_llama_index-3.3.1-py3-none-any.whl (26 kB)\n",
      "Downloading aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading openinference_instrumentation-0.1.23-py3-none-any.whl (19 kB)\n",
      "Downloading openinference_semantic_conventions-0.1.14-py3-none-any.whl (9.2 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Downloading aiohappyeyeballs-2.4.8-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: filetype, dirtyjson, zipp, wrapt, tqdm, tenacity, regex, PyYAML, pydantic-core, propcache, openinference-semantic-conventions, networkx, mypy-extensions, multidict, marshmallow, joblib, greenlet, fsspec, frozenlist, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, pydantic, nltk, importlib-metadata, deprecated, aiosignal, opentelemetry-api, dataclasses-json, aiohttp, opentelemetry-semantic-conventions, llama-index-core, opentelemetry-sdk, opentelemetry-instrumentation, openinference-instrumentation, openinference-instrumentation-llama-index, llama-index-callbacks-arize-phoenix\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.8 aiohttp-3.11.13 aiosignal-1.3.2 annotated-types-0.7.0 async-timeout-5.0.1 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 frozenlist-1.5.0 fsspec-2025.2.0 greenlet-3.1.1 importlib-metadata-8.5.0 joblib-1.4.2 llama-index-callbacks-arize-phoenix-0.4.0 llama-index-core-0.12.22 marshmallow-3.26.1 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 nltk-3.9.1 openinference-instrumentation-0.1.23 openinference-instrumentation-llama-index-3.3.1 openinference-semantic-conventions-0.1.14 opentelemetry-api-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 propcache-0.3.0 pydantic-2.10.6 pydantic-core-2.27.2 regex-2024.11.6 tenacity-9.0.0 tiktoken-0.9.0 tqdm-4.67.1 typing-inspect-0.9.0 wrapt-1.17.2 yarl-1.18.3 zipp-3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U llama-index-callbacks-arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Arize Phoenix for logging/observability\n",
    "import llama_index.core\n",
    "import os\n",
    "\n",
    "PHOENIX_API_KEY = os.getenv(\"ARIZE_PHOENIX_API_KEY\")\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents into LlamaCloud\n",
    "\n",
    "Download the following Wikipedia pages into PDFs by either pressing Ctrl-P/Cmd-P or right-clicking and selecting \"Print\" and then \"Save as PDF\" as the destination.\n",
    "- [New York City](https://en.wikipedia.org/wiki/New_York_City)\n",
    "- [Los Angeles](https://en.wikipedia.org/wiki/Los_Angeles)\n",
    "- [Chicago](https://en.wikipedia.org/wiki/Chicago)\n",
    "- [Houston](https://en.wikipedia.org/wiki/Houston)\n",
    "- [Miami](https://en.wikipedia.org/wiki/Miami)\n",
    "- [Seattle](https://en.wikipedia.org/wiki/Seattle)\n",
    "\n",
    "After that, create a new index in LlamaCloud and upload your PDFs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Database\n",
    "\n",
    "The SQL database in this example will be created in memory and will contain three columns: the city name, the city's population, and the state the city is located in. The table creation and the information for each city is shown in the snippets below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.22-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama-index)\n",
      "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.22 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index) (0.12.22)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.8-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.3.25-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.4.6-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index) (3.9.1)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Using cached openai-1.65.4-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/mahesh/.local/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.22->llama-index) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/lib/python3/dist-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (9.0.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.17.2)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.13-py3-none-any.whl.metadata (800 bytes)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pandas in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk>3.8.1->llama-index) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/mahesh/.local/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/mahesh/.local/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (2.4.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/lib/python3/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.3.1)\n",
      "Collecting certifi>=2024.7.4 (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: anyio in /home/mahesh/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.22->llama-index) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mahesh/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.22->llama-index) (3.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mahesh/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.22->llama-index) (0.14.0)\n",
      "Collecting llama-cloud-services>=0.6.2 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.3-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/mahesh/.local/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /home/mahesh/.local/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mahesh/.local/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/mahesh/.local/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mahesh/.local/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.26.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mahesh/.local/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.22->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mahesh/.local/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.22->llama-index) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mahesh/.local/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mahesh/.local/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/mahesh/.local/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.2.2)\n",
      "Collecting click (from nltk>3.8.1->llama-index)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.2->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/mahesh/.local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.22->llama-index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.16.0)\n",
      "Downloading llama_index-0.12.22-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.8-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_llms_openai-0.3.25-py3-none-any.whl (16 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.6-py3-none-any.whl (40 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading llama_cloud-0.1.13-py3-none-any.whl (253 kB)\n",
      "Downloading llama_parse-0.6.2-py3-none-any.whl (4.8 kB)\n",
      "Using cached openai-1.65.4-py3-none-any.whl (473 kB)\n",
      "Downloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading llama_cloud_services-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: striprtf, python-dotenv, pypdf, click, certifi, beautifulsoup4, openai, llama-cloud, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "Successfully installed beautifulsoup4-4.13.3 certifi-2025.1.31 click-8.1.8 llama-cloud-0.1.13 llama-cloud-services-0.6.3 llama-index-0.12.22 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.8 llama-index-llms-openai-0.3.25 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.6 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.2 openai-1.65.4 pypdf-5.3.1 python-dotenv-1.0.1 striprtf-0.0.26\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    ")\n",
    "\n",
    "Settings.llm = OpenAI(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\", future=True)\n",
    "metadata_obj = MetaData()\n",
    "\n",
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"state\", String(16), nullable=False),\n",
    ")\n",
    "\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('New York City', 8336000, 'New York'), ('Los Angeles', 3822000, 'California'), ('Chicago', 2665000, 'Illinois'), ('Houston', 2303000, 'Texas'), ('Miami', 449514, 'Florida'), ('Seattle', 749256, 'Washington')]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "rows = [\n",
    "    {\"city_name\": \"New York City\", \"population\": 8336000, \"state\": \"New York\"},\n",
    "    {\"city_name\": \"Los Angeles\", \"population\": 3822000, \"state\": \"California\"},\n",
    "    {\"city_name\": \"Chicago\", \"population\": 2665000, \"state\": \"Illinois\"},\n",
    "    {\"city_name\": \"Houston\", \"population\": 2303000, \"state\": \"Texas\"},\n",
    "    {\"city_name\": \"Miami\", \"population\": 449514, \"state\": \"Florida\"},\n",
    "    {\"city_name\": \"Seattle\", \"population\": 749256, \"state\": \"Washington\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    cursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a query engine based on SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"city_stats\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaCloud Index\n",
    "\n",
    "Create an index and a query engine around the index you've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
    "\n",
    "index = LlamaCloudIndex(\n",
    "    name=\"yummy-meerkat-2025-03-05\", \n",
    "    project_name=\"Default\",\n",
    "    organization_id=\"a17977ff-6c02-4b74-ab89-2e2396d01310\",\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    ")\n",
    "\n",
    "llama_cloud_query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a query engine tool around these query engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query over\"\n",
    "        \" a table containing: city_stats, containing the population/state of\"\n",
    "        \" each city located in the USA.\"\n",
    "    ),\n",
    "    name=\"sql_tool\"\n",
    ")\n",
    "\n",
    "cities = [\"New York City\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Miami\", \"Seattle\"]\n",
    "llama_cloud_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=llama_cloud_query_engine,\n",
    "    description=(\n",
    "        f\"Useful for answering semantic questions about certain cities in the US.\"\n",
    "    ),\n",
    "    name=\"llama_cloud_tool\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Agent Around the Query Engines\n",
    "\n",
    "We'll create a workflow that acts as an agent around the two query engines. In this workflow, we need four events:\n",
    "1. `GatherToolsEvent`: Gets all tools that need to be called (which is determined by the LLM).\n",
    "2. `ToolCallEvent`: An individual tool call. Multiple of these events will be triggered at the same time.\n",
    "3. `ToolCallEventResult`: Gets result from a tool call.\n",
    "4. `GatherEvent`: Returned from dispatcher that triggers the `ToolCallEvent`.\n",
    "\n",
    "This workflow consists of the following steps:\n",
    "1. `chat()`: Appends the message to the chat history. This chat history is fed into the LLM, along with the given tools, and the LLM determines which tools to call. This returns a `GatherToolsEvent`.\n",
    "2. `dispatch_calls()`: Triggers a `ToolCallEvent` for each tool call given in the `GatherToolsEvent` using `send_event()`. Returns a `GatherEvent` with the number of tool calls.\n",
    "3. `call_tool()`: Calls an individual tool. This step will run multiple times if there is more than one tool call. This step calls the tool and appends the result as a chat message to the chat history. It returns a `ToolCallEventResult` with the result of the tool call.\n",
    "4. `gather()`: Gathers the results from all tool calls using `collect_events()`. Waits for all tool calls to finish, then feeds chat history (following all tool calls) into the LLM. Returns the response from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "from llama_index.core.tools import BaseTool\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.llms.llm import ToolSelection, LLM\n",
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    "    Context\n",
    ")\n",
    "from llama_index.core.base.response.schema import Response\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "class InputEvent(Event):\n",
    "    \"\"\"Input event.\"\"\"\n",
    "\n",
    "class GatherToolsEvent(Event):\n",
    "    \"\"\"Gather Tools Event\"\"\"\n",
    "\n",
    "    tool_calls: Any\n",
    "\n",
    "class ToolCallEvent(Event):\n",
    "    \"\"\"Tool Call event\"\"\"\n",
    "\n",
    "    tool_call: ToolSelection\n",
    "\n",
    "class ToolCallEventResult(Event):\n",
    "    \"\"\"Tool call event result.\"\"\"\n",
    "\n",
    "    msg: ChatMessage\n",
    "\n",
    "class RouterOutputAgentWorkflow(Workflow):\n",
    "    \"\"\"Custom router output agent workflow.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        tools: List[BaseTool],\n",
    "        timeout: Optional[float] = 10.0,\n",
    "        disable_validation: bool = False,\n",
    "        verbose: bool = False,\n",
    "        llm: Optional[LLM] = None,\n",
    "        chat_history: Optional[List[ChatMessage]] = None,\n",
    "    ):\n",
    "        \"\"\"Constructor.\"\"\"\n",
    "\n",
    "        super().__init__(timeout=timeout, disable_validation=disable_validation, verbose=verbose)\n",
    "\n",
    "        self.tools: List[BaseTool] = tools\n",
    "        self.tools_dict: Optional[Dict[str, BaseTool]] = {tool.metadata.name: tool for tool in self.tools}\n",
    "        self.llm: LLM = llm or OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "        self.chat_history: List[ChatMessage] = chat_history or []\n",
    "    \n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets Chat History\"\"\"\n",
    "\n",
    "        self.chat_history = []\n",
    "\n",
    "    @step()\n",
    "    async def prepare_chat(self, ev: StartEvent) -> InputEvent:\n",
    "        message = ev.get(\"message\")\n",
    "        if message is None:\n",
    "            raise ValueError(\"'message' field is required.\")\n",
    "        \n",
    "        # add msg to chat history\n",
    "        chat_history = self.chat_history\n",
    "        chat_history.append(ChatMessage(role=\"user\", content=message))\n",
    "        return InputEvent()\n",
    "\n",
    "    @step()\n",
    "    async def chat(self, ev: InputEvent) -> GatherToolsEvent | StopEvent:\n",
    "        \"\"\"Appends msg to chat history, then gets tool calls.\"\"\"\n",
    "\n",
    "        # Put msg into LLM with tools included\n",
    "        chat_res = await self.llm.achat_with_tools(\n",
    "            self.tools,\n",
    "            chat_history=self.chat_history,\n",
    "            verbose=self._verbose,\n",
    "            allow_parallel_tool_calls=True\n",
    "        )\n",
    "        tool_calls = self.llm.get_tool_calls_from_response(chat_res, error_on_no_tool_call=False)\n",
    "        \n",
    "        ai_message = chat_res.message\n",
    "        self.chat_history.append(ai_message)\n",
    "        if self._verbose:\n",
    "            print(f\"Chat message: {ai_message.content}\")\n",
    "\n",
    "        # no tool calls, return chat message.\n",
    "        if not tool_calls:\n",
    "            return StopEvent(result=ai_message.content)\n",
    "\n",
    "        return GatherToolsEvent(tool_calls=tool_calls)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def dispatch_calls(self, ctx: Context, ev: GatherToolsEvent) -> ToolCallEvent:\n",
    "        \"\"\"Dispatches calls.\"\"\"\n",
    "\n",
    "        tool_calls = ev.tool_calls\n",
    "        await ctx.set(\"num_tool_calls\", len(tool_calls))\n",
    "\n",
    "        # trigger tool call events\n",
    "        for tool_call in tool_calls:\n",
    "            ctx.send_event(ToolCallEvent(tool_call=tool_call))\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @step()\n",
    "    async def call_tool(self, ev: ToolCallEvent) -> ToolCallEventResult:\n",
    "        \"\"\"Calls tool.\"\"\"\n",
    "\n",
    "        tool_call = ev.tool_call\n",
    "\n",
    "        # get tool ID and function call\n",
    "        id_ = tool_call.tool_id\n",
    "\n",
    "        if self._verbose:\n",
    "            print(f\"Calling function {tool_call.tool_name} with msg {tool_call.tool_kwargs}\")\n",
    "\n",
    "        # call function and put result into a chat message\n",
    "        tool = self.tools_dict[tool_call.tool_name]\n",
    "        output = await tool.acall(**tool_call.tool_kwargs)\n",
    "        msg = ChatMessage(\n",
    "            name=tool_call.tool_name,\n",
    "            content=str(output),\n",
    "            role=\"tool\",\n",
    "            additional_kwargs={\n",
    "                \"tool_call_id\": id_,\n",
    "                \"name\": tool_call.tool_name\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return ToolCallEventResult(msg=msg)\n",
    "    \n",
    "    @step(pass_context=True)\n",
    "    async def gather(self, ctx: Context, ev: ToolCallEventResult) -> StopEvent | None:\n",
    "        \"\"\"Gathers tool calls.\"\"\"\n",
    "        # wait for all tool call events to finish.\n",
    "        tool_events = ctx.collect_events(ev, [ToolCallEventResult] * await ctx.get(\"num_tool_calls\"))\n",
    "        if not tool_events:\n",
    "            return None\n",
    "        \n",
    "        for tool_event in tool_events:\n",
    "            # append tool call chat messages to history\n",
    "            self.chat_history.append(tool_event.msg)\n",
    "        \n",
    "        # # after all tool calls finish, pass input event back, restart agent loop\n",
    "        return InputEvent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the workflow instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = RouterOutputAgentWorkflow(tools=[sql_tool, llama_cloud_tool], verbose=True, timeout=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-index-utils-workflow\n",
      "  Downloading llama_index_utils_workflow-0.3.0-py3-none-any.whl.metadata (665 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-utils-workflow) (0.12.22)\n",
      "Collecting pyvis<0.4.0,>=0.3.2 (from llama-index-utils-workflow)\n",
      "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/mahesh/.local/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/lib/python3/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (9.0.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/mahesh/.local/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.17.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (8.33.0)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /home/mahesh/.local/lib/python3.10/site-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.1.6)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow)\n",
      "  Downloading jsonpickle-4.0.2-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.4.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/mahesh/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.18.3)\n",
      "Requirement already satisfied: decorator in /home/mahesh/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/mahesh/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/mahesh/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/mahesh/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.8.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/mahesh/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/lib/python3/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.11.2)\n",
      "Requirement already satisfied: stack_data in /home/mahesh/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/mahesh/.local/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2>=2.9.6->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.0.1)\n",
      "Requirement already satisfied: click in /home/mahesh/.local/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/mahesh/.local/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/mahesh/.local/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mahesh/.local/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/mahesh/.local/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mahesh/.local/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mahesh/.local/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mahesh/.local/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mahesh/.local/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.26.1)\n",
      "Requirement already satisfied: anyio in /home/mahesh/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mahesh/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mahesh/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/mahesh/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.8.4)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/mahesh/.local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (24.2)\n",
      "Requirement already satisfied: wcwidth in /home/mahesh/.local/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.13)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/mahesh/.local/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/mahesh/.local/lib/python3.10/site-packages (from stack_data->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/mahesh/.local/lib/python3.10/site-packages (from stack_data->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/mahesh/.local/lib/python3.10/site-packages (from stack_data->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.3)\n",
      "Downloading llama_index_utils_workflow-0.3.0-py3-none-any.whl (2.8 kB)\n",
      "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m434.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading jsonpickle-4.0.2-py3-none-any.whl (46 kB)\n",
      "Installing collected packages: jsonpickle, pyvis, llama-index-utils-workflow\n",
      "Successfully installed jsonpickle-4.0.2 llama-index-utils-workflow-0.3.0 pyvis-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-utils-workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class '__main__.ToolCallEventResult'>\n",
      "<class '__main__.GatherToolsEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.ToolCallEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.InputEvent'>\n",
      "workflow_all_flows.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(RouterOutputAgentWorkflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat\n",
      "Step prepare_chat produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: None\n",
      "Step chat produced event GatherToolsEvent\n",
      "Running step dispatch_calls\n",
      "Step dispatch_calls produced no event\n",
      "Running step call_tool\n",
      "Calling function sql_tool with msg {'input': 'SELECT city FROM city_stats ORDER BY population DESC LIMIT 1'}\n",
      "Step call_tool produced event ToolCallEventResult\n",
      "Running step gather\n",
      "Step gather produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: New York City has the highest population.\n",
      "Step chat produced event StopEvent\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "New York City has the highest population."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "result = await wf.run(message=\"Which city has the highest population?\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat\n",
      "Step prepare_chat produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: None\n",
      "Step chat produced event GatherToolsEvent\n",
      "Running step dispatch_calls\n",
      "Step dispatch_calls produced no event\n",
      "Running step call_tool\n",
      "Calling function llama_cloud_tool with msg {'input': 'What state is Houston located in?'}\n",
      "Step call_tool produced event ToolCallEventResult\n",
      "Running step gather\n",
      "Step gather produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: Houston is located in the state of Texas.\n",
      "Step chat produced event StopEvent\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Houston is located in the state of Texas."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await wf.run(message=\"What state is Houston located in?\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat\n",
      "Step prepare_chat produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: None\n",
      "Step chat produced event GatherToolsEvent\n",
      "Running step dispatch_calls\n",
      "Step dispatch_calls produced no event\n",
      "Running step call_tool\n",
      "Calling function llama_cloud_tool with msg {'input': 'Where is the Space Needle located?'}\n",
      "Step call_tool produced event ToolCallEventResult\n",
      "Running step gather\n",
      "Step gather produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: The Space Needle is located in Seattle.\n",
      "Step chat produced event StopEvent\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The Space Needle is located in Seattle."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await wf.run(message=\"Where is the Space Needle located?\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat\n",
      "Step prepare_chat produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: None\n",
      "Step chat produced event GatherToolsEvent\n",
      "Running step dispatch_calls\n",
      "Step dispatch_calls produced no event\n",
      "Running step call_tool\n",
      "Calling function llama_cloud_tool with msg {'input': 'List all of the places to visit in Miami'}\n",
      "Step call_tool produced event ToolCallEventResult\n",
      "Running step gather\n",
      "Step gather produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: Here is a list of places to visit in Miami: Bayfront Park, Museum Park, Tropical Park, Peacock Park, Virginia Key, Watson Island, Zoo Miami, Jungle Island, Miami Seaquarium, Monkey Jungle, Coral Castle, Charles Deering Estate, Fairchild Tropical Botanic Garden, Key Biscayne, South Beach, Lincoln Road, Bayside Marketplace, Downtown Miami, Brickell City Centre, Art Deco District, Miami Open, Art Basel, Winter Music Conference, South Beach Wine and Food Festival, Mercedes-Benz Fashion Week Miami, Adrienne Arsht Center for the Performing Arts, Olympia Theater, Wertheim Performing Arts Center, Fair Expo Center, Tower Theater, Bayfront Park Amphitheater, Miami International Film Festival, New World School of the Arts, Miami Fashion Week, Mercedes-Benz Fashion Force, Frost Art Museum, Calle Ocho Festival, Vizcaya Museum, The Kampong, The Barnacle Historic State Park, Little Havana, West Flagler, Flagami, Allapattah, Midtown, Edgewater, Wynwood, Design District, Upper Eastside, Little Haiti, Overtown, and Liberty City.\n",
      "Step chat produced event StopEvent\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here is a list of places to visit in Miami: Bayfront Park, Museum Park, Tropical Park, Peacock Park, Virginia Key, Watson Island, Zoo Miami, Jungle Island, Miami Seaquarium, Monkey Jungle, Coral Castle, Charles Deering Estate, Fairchild Tropical Botanic Garden, Key Biscayne, South Beach, Lincoln Road, Bayside Marketplace, Downtown Miami, Brickell City Centre, Art Deco District, Miami Open, Art Basel, Winter Music Conference, South Beach Wine and Food Festival, Mercedes-Benz Fashion Week Miami, Adrienne Arsht Center for the Performing Arts, Olympia Theater, Wertheim Performing Arts Center, Fair Expo Center, Tower Theater, Bayfront Park Amphitheater, Miami International Film Festival, New World School of the Arts, Miami Fashion Week, Mercedes-Benz Fashion Force, Frost Art Museum, Calle Ocho Festival, Vizcaya Museum, The Kampong, The Barnacle Historic State Park, Little Havana, West Flagler, Flagami, Allapattah, Midtown, Edgewater, Wynwood, Design District, Upper Eastside, Little Haiti, Overtown, and Liberty City."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await wf.run(message=\"List all of the places to visit in Miami.\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat\n",
      "Step prepare_chat produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: None\n",
      "Step chat produced event GatherToolsEvent\n",
      "Running step dispatch_calls\n",
      "Step dispatch_calls produced no event\n",
      "Running step call_tool\n",
      "Calling function llama_cloud_tool with msg {'input': 'How do people in Chicago get around?'}\n",
      "Step call_tool produced event ToolCallEventResult\n",
      "Running step gather\n",
      "Step gather produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: People in Chicago get around using a variety of transportation options including the Chicago Transit Authority (CTA) buses and trains, the Metra commuter rail service, Pace buses, bike-sharing systems like Divvy, electric scooter programs, and inter-city bus services like Greyhound Lines and Megabus.\n",
      "Step chat produced event StopEvent\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "People in Chicago get around using a variety of transportation options including the Chicago Transit Authority (CTA) buses and trains, the Metra commuter rail service, Pace buses, bike-sharing systems like Divvy, electric scooter programs, and inter-city bus services like Greyhound Lines and Megabus."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await wf.run(message=\"How do people in Chicago get around?\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat\n",
      "Step prepare_chat produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: None\n",
      "Step chat produced event GatherToolsEvent\n",
      "Running step dispatch_calls\n",
      "Step dispatch_calls produced no event\n",
      "Running step call_tool\n",
      "Calling function llama_cloud_tool with msg {'input': 'What is the historical name of Los Angeles?'}\n",
      "Step call_tool produced event ToolCallEventResult\n",
      "Running step gather\n",
      "Step gather produced event InputEvent\n",
      "Running step chat\n",
      "Chat message: The historical name of Los Angeles is El Pueblo de Nuestra Señora la Reina de los Ángeles.\n",
      "Step chat produced event StopEvent\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The historical name of Los Angeles is El Pueblo de Nuestra Señora la Reina de los Ángeles."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await wf.run(message=\"What is the historical name of Los Angeles?\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.43.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/lib/python3/dist-packages (from streamlit) (9.0.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (9.0.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /home/mahesh/.local/lib/python3.10/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/mahesh/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/mahesh/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mahesh/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas<3,>=1.4.0->streamlit) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mahesh/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mahesh/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mahesh/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/mahesh/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/mahesh/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/mahesh/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/mahesh/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.43.0-py2.py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading narwhals-1.29.1-py3-none-any.whl (308 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toml, smmap, narwhals, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 gitdb-4.0.12 gitpython-3.1.44 narwhals-1.29.1 pydeck-0.9.1 smmap-5.0.2 streamlit-1.43.0 toml-0.10.2 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
